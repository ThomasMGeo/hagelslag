#!/usr/bin/env python
import argparse
from multiprocessing import Pool
from hagelslag.util.Config import Config
from hagelslag.processing.TrackProcessing import TrackProcessor
from datetime import timedelta
import pandas as pd
import numpy as np
import os


def main():
    parser = argparse.ArgumentParser("Hagelslag Data Processor")
    parser.add_argument("config", help="Configuration file")
    parser.add_argument("-p", "--proc", type=int, default=1,
                        help="Number of processors")
    args = parser.parse_args()
    required = ['dates', 'start_hour', 'end_hour', 'ensemble_members', 
               'watershed_variable', 'model_path', "ensemble_name",
               'model_watershed_params', 'object_matcher_params', 
               'track_matcher_params', 'size_filter', 'gaussian_window',
               'mesh_path', 'mesh_watershed_params', 
               'storm_variables', 'potential_variables', 
               'variable_statistics','model_map_file',
               'csv_path', 'geojson_path', 'train', 'proj']
    config = Config(args.config, required_attributes=required)
    if args.proc > 1:
        pool = Pool(args.proc)
        for run_date in config.dates:
            for member in config.ensemble_members:
                pool.apply_async(process_ensemble_member, (run_date, member, config))
        pool.close()
        pool.join()
    else:
        for run_date in config.dates:
            for member in config.ensemble_members:
                apply(process_ensemble_member, (run_date, member, config))
    return

def process_ensemble_member(run_date, member, config):
    """
    Find forecast and observed tracks for one run of a storm-scale ensemble member.

    :param run_date: datetime object containing the date of the model run
    :param member: name of the ensemble member
    :param config: Config object containing model parameters
    """
    print "Starting", run_date, member
    start_date = run_date + timedelta(hours=config.start_hour*3600)
    end_date = run_date + timedelta(seconds=config.end_hour*3600)
    track_proc = TrackProcessor(run_date,
                                start_date,
                                end_date,
                                config.ensemble_name,
                                member,
                                config.watershed_variable,
                                config.model_path,
                                config.model_map_file,
                                config.model_watershed_params,
                                config.object_matcher_params,
                                config.track_matcher_params,
                                config.size_filter,
                                config.gaussian_window,
                                mrms_path=config.mesh_path,
                                mrms_variable=config.mrms_variable,
                                mrms_watershed_params=config.mesh_watershed_params,
                                single_step=config.single_step)
    print "Find model tracks", run_date, member
    model_tracks = track_proc.find_model_tracks()
    print "Extract model attributes", run_date, member
    track_proc.extract_model_attributes(model_tracks,
                                        config.storm_variables,
                                        config.potential_variables)
    if config.train and len(model_tracks) > 0:
        print "Find obs tracks", run_date, member
        mrms_tracks = track_proc.find_mrms_tracks()
        if len(mrms_tracks) > 0 and len(model_tracks) > 0:
            track_pairings = track_proc.match_tracks(model_tracks, mrms_tracks)
            track_proc.match_hail_sizes(model_tracks, mrms_tracks, track_pairings)
            track_errors = track_proc.calc_track_errors(model_tracks,
                                                        mrms_tracks,
                                                        track_pairings)
            print "Output data", run_date, member
            forecast_data = make_forecast_track_data(model_tracks, run_date, member,
                                                     config, track_proc.model_grid.proj, mrms_tracks, track_errors)
            obs_data = make_obs_track_data(mrms_tracks, member, run_date, config, track_proc.model_grid.proj)
            #if not os.access(config.csv_path + run_date.strftime("%Y%m%d"), os.R_OK):
            #    try:
            #        os.mkdir(config.csv_path + run_date.strftime("%Y%m%d"))
            #    except:
            #        print config.csv_path + run_date.strftime("%Y%m%d") + " already exists"
            for table_name, table_data in obs_data.iteritems():
                table_data.to_csv(config.csv_path + "{0}_{1}_{2}_{3}.csv".format(table_name,
                                                                                 "obs",
                                                                                 member,
                                                                                 run_date.strftime("%Y%m%d")),
                                  na_rep="nan",
                                  float_format="%0.5f",
                                  index=False)

        else:
            forecast_data = make_forecast_track_data(model_tracks, run_date, member, config, track_proc.model_grid.proj)
    elif len(model_tracks) > 0:
        forecast_data = make_forecast_track_data(model_tracks, run_date, member, config, track_proc.model_grid.proj)
    else:
        forecast_data = {}
    for table_name, table_data in forecast_data.iteritems():
        table_data.to_csv(config.csv_path + "{0}_{1}_{2}_{3}.csv".format(table_name,
                                                                         config.ensemble_name,
                                                                         member,
                                                                         run_date.strftime("%Y%m%d")),
                          na_rep="nan",
                          float_format="%0.5f",
                          index=False)
    return


def make_forecast_track_data(forecast_tracks, run_date, member, config, proj, observed_tracks=None, track_errors=None):
    """
    Transform forecast track timesteps to csv and geojson format and output to files.

    :param forecast_tracks: list of storm tracks found in the forecast model
    :param run_date: datetime object with the start date and time of the model run
    :param member: name of the ensemble member
    :param config: Config object containing output parameters
    :param observed_tracks: list of storm trakcs found in the observation grid
    :param track_errors: pandas dataframe containing track error information
    """
    forecast_total_track_columns = ["Track_ID", "Start_Date", "End_Date",
                                    "Duration", "Ensemble_Name",
                                    "Ensemble_Member", "Object_Variable", "Obs_Track_ID",
                                    "Translation_Error_X", "Translation_Error_Y",
                                    "Start_Time_Error", "End_Time_Error"]
    forecast_step_track_columns = ["Step_ID", "Track_ID", "Date",
                                   "Forecast_Hour", "Valid_Hour_UTC", "Duration",
                                   "Centroid_Lon", "Centroid_Lat"]
    var_stats = []
    for var in config.storm_variables + config.potential_variables:
        for stat in config.variable_statistics:
            var_stats.append(var + "_" + stat)
    forecast_step_track_columns = forecast_step_track_columns + var_stats + ["Hail_Size"]
    forecast_data = {}
    forecast_data['track_total'] = pd.DataFrame(columns=forecast_total_track_columns)
    forecast_data['track_step'] = pd.DataFrame(columns=forecast_step_track_columns)
    track_step_count = 0
    for f, forecast_track in enumerate(forecast_tracks):
        track_id = "{0}_{1}_{2}_{3:02d}_{4:02d}_{5:03d}".format(member,
                                                                config.watershed_variable,
                                                                run_date.strftime("%Y%m%d-%H%M"),
                                                                forecast_track.start_time,
                                                                forecast_track.end_time,
                                                                f,
                                                                )
        start_date = run_date + timedelta(seconds=3600 * forecast_track.start_time)
        end_date = run_date + timedelta(seconds=3600 * forecast_track.end_time)
        duration = (end_date - start_date).total_seconds() / 3600.0 + 1
        ensemble_name = config.ensemble_name
        if config.train and track_errors is not None:
            if not np.isnan(track_errors.ix[f,0]):
                obs_track_num = track_errors.ix[f,0]
                obs_track_id = "obs_{0}_{1}_{2:02d}_{3:02d}_{4:03d}".format(member,
                                             run_date.strftime("%Y%m%d-%H%M"),
                                             observed_tracks[obs_track_num].start_time,
                                             observed_tracks[obs_track_num].end_time,
                                             obs_track_num)
            else:
                obs_track_id = "None"
            track_error_row = [obs_track_id] + track_errors.ix[f,1:].tolist()
        else:
            track_error_row = [np.nan] * 5
        forecast_data['track_total'].loc[f] = [track_id, start_date, end_date, duration,
                                                ensemble_name, member,
                                                config.watershed_variable] + track_error_row
        for s, step in enumerate(forecast_track.times):
            step_id = track_id + "_{0:02d}".format(s)
            step_date = run_date + timedelta(seconds=3600 * step)
            valid_hour_utc = step_date.hour
            step_duration = s + 1
            centroid_lon, centroid_lat = proj(*forecast_track.center_of_mass(step), inverse=True)
            var_stat_vals = []
            for attribute in config.storm_variables + config.potential_variables:
                for statistic in config.variable_statistics:
                    var_stat_vals.append(forecast_track.calc_attribute_statistic(attribute, statistic, step))
            if forecast_track.observations is not None:
                hail_size = forecast_track.observations[s]
            else:
                hail_size = 0
            record = [step_id, track_id, step_date, step, valid_hour_utc,
                      step_duration, centroid_lon, centroid_lat] + var_stat_vals + [hail_size]
            forecast_data['track_step'].loc[track_step_count] = record
            track_step_count += 1
        path_parts = [run_date.strftime("%Y%m%d"), member]
        full_path = []
        for part in path_parts:
            full_path.append(part)
            if not os.access(config.geojson_path + "/".join(full_path), os.R_OK):
                try:
                    os.mkdir(config.geojson_path + "/".join(full_path))
                except OSError:
                    print "directory already created"

        json_filename = config.geojson_path + "/".join(full_path) + \
                        "/{0}_{1}_{2}_model_track_{3:03d}.json".format(ensemble_name,
                                                                       run_date.strftime("%Y%m%d"),
                                                                       member,
                                                                       f)
        json_metadata = dict(id=track_id,
                             ensemble_name=ensemble_name,
                             ensemble_member=member,
                             duration=duration)
        if config.train and track_errors is not None:
            json_metadata['obs_track_id'] = obs_track_id
        forecast_track.to_geojson(json_filename, proj, json_metadata)
    return forecast_data


def make_obs_track_data(obs_tracks, member, run_date, config, proj):
    obs_total_track_columns = ["Track_ID", "Start_Date", "End_Date", "Duration"]
    obs_step_track_columns = ["Step_ID", "Track_ID","Date", "Forecast_Hour",
                                "Valid_Hour_UTC", "Duration",
                                "Centroid_Lon", "Centroid_Lat"]
    var_stats = []
    for stat in config.variable_statistics:
        var_stats.append("MESH_" + stat)
    obs_step_track_columns = obs_step_track_columns + var_stats
    obs_data = {}
    obs_data['track_total'] = pd.DataFrame(columns=obs_total_track_columns)
    obs_data['track_step'] = pd.DataFrame(columns=obs_step_track_columns)
    track_step_count = 0
    for o, obs_track in enumerate(obs_tracks):
        obs_track_id = "obs_{0}_{1}_{2:02d}_{3:02d}_{4:03d}".format(member,
                                                                    run_date.strftime("%Y%m%d-%H%M"),
                                                                    obs_track.start_time,
                                                                    obs_track.end_time,
                                                                    o)
        start_date = run_date + timedelta(seconds=3600 * obs_track.start_time)
        end_date = run_date + timedelta(seconds=3600 * obs_track.end_time)
        duration = (end_date - start_date).total_seconds() / 3600.0 + 1
        obs_data['track_total'].loc[o] = [obs_track_id, start_date, end_date, duration]
        for s, step in enumerate(obs_track.times):
            step_id = obs_track_id + "_{0:02d}".format(s)
            step_date = run_date + timedelta(seconds=3600 * step)
            valid_hour_utc = step_date.hour
            step_duration = s + 1
            centroid_lon, centroid_lat = proj(*obs_track.center_of_mass(step), inverse=True)
            var_stat_vals = []
            for statistic in config.variable_statistics:
                var_stat_vals.append(obs_track.calc_timestep_statistic(statistic, step))
            record = [step_id, obs_track_id, step_date, step,
                      valid_hour_utc, step_duration, centroid_lon, centroid_lat] + var_stat_vals
            obs_data['track_step'].loc[track_step_count] = record
            track_step_count += 1
        path_parts = [run_date.strftime("%Y%m%d"), member]
        full_path = []
        for part in path_parts:
            full_path.append(part)
            if not os.access(config.geojson_path + "/".join(full_path), os.R_OK):
                try:
                    os.mkdir(config.geojson_path + "/".join(full_path))
                except OSError:
                    print "directory already created"

        json_filename = config.geojson_path + "/".join(full_path) + \
                        "/{0}_{1}_{2}_obs_track_{3:03d}.json".format("mesh",
                                                                     run_date.strftime("%Y%m%d"),
                                                                     member,
                                                                     o)
        json_metadata = dict(id=obs_track_id,
                             ensemble_member=member,
                             duration=duration)
        obs_track.to_geojson(json_filename, proj, json_metadata)
    return obs_data


if __name__ == "__main__":
    main()
